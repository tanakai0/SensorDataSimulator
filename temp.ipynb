{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# conditional random fields\n",
    "import ace_sklearn_crfsuite\n",
    "from ace_sklearn_crfsuite import metrics\n",
    "\n",
    "# self-made\n",
    "import src.analysis as analysis\n",
    "import src.anomaly_model as anomaly_model\n",
    "import src.utils as utils\n",
    "import src.sensor_model as sensor_model\n",
    "\n",
    "working_path = Path().resolve()\n",
    "layout_database_path = working_path / \"layout_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def fall_feature_sliding(mat, time_step, window_len, nrt_type = \"instantaneous\"):\n",
    "    \"\"\"\n",
    "    Calculate features for fall detection.\n",
    "    The feature includes;\n",
    "    1: non response time of all sensors at the present time\n",
    "    2: maximum height of the edge of the non response time sequence in the left / right part of the window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : nummpy.ndarray of bool\n",
    "        Raw sensor data matrix.\n",
    "        mat[i][j] = j-th sensor state at i-th time.\n",
    "    time_step : float\n",
    "        Time step length [seconds] of mat = mat[1][0] - mat[0][0].\n",
    "    window_len : int\n",
    "        Length of window.\n",
    "        window_len is the number of columns in mat.\n",
    "        window_len must be an odd number.\n",
    "    mode : int\n",
    "        \"instantaneous\" : instantaneous non response time\n",
    "        \"sum\" : sum in the window\n",
    "        \"max\" : max in the window\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    feature : numpy.ndarray\n",
    "        (number of time, dimension of feature).\n",
    "        feature[t] = feature vector of the t-th time.\n",
    "        feature.shape[0] == mat.shape[0].\n",
    "        Let w be a (window_len - 1)/2.\n",
    "        feature.shape[i] is a vector made from mat[i-w/2:i+w/2+1] for any w/2 <= i <mat.shape[0]-w/2\n",
    "        feature.shape[i] is a vector made from mat[0:i+w/2+1] for any i < w/2.\n",
    "        feature.shape[i] is a vector made from mat[i-w/2:mat.shape[0]] for any i >= mat.shape[0]-w/2.\n",
    "        sensor_num_dic saves the realtion between index of sensors and index of features.\n",
    "    \"\"\"\n",
    "    feature = np.zeros((mat.shape[0], mat.shape[1]), dtype = np.int32)\n",
    "    for i, item in enumerate(gen_fall_feature_sliding(mat, time_step, window_len, nrt_type)):\n",
    "        feature[i] = item\n",
    "    return feature\n",
    "\n",
    "def gen_fall_feature_sliding(mat, time_step, window_len, nrt_type = \"instantaneous\"):\n",
    "    \"\"\"\n",
    "    Generator.\n",
    "    Calculate features for fall detection.\n",
    "    The feature includes;\n",
    "    1: non response time of all sensors at the present time\n",
    "    2: maximum height of the edge of the non response time sequence in the left / right part of the window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : nummpy.ndarray of bool\n",
    "        Raw sensor data matrix.\n",
    "        mat[i][j] = j-th sensor state at i-th time.\n",
    "    time_step : float\n",
    "        Time step length [seconds] of mat = mat[1][0] - mat[0][0].\n",
    "    window_len : int\n",
    "        Length of window.\n",
    "        window_len is the number of columns in mat.\n",
    "        window_len must be an odd number.\n",
    "    mode : int\n",
    "        \"instantaneous\" : instantaneous non response time\n",
    "        \"sum\" : sum in the window\n",
    "        \"max\" : max in the window\n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    feature : numpy.ndarray\n",
    "        (dimension of feature, ).\n",
    "    \"\"\"\n",
    "\n",
    "    def edge_detection(window_data):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        window_data : numpy.ndarray\n",
    "            Non response time. The shape is (window_len, num. of sensors).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (left_edge_height, right_edge_height) : tuple of int\n",
    "            left_edge_height is a maximum height of the edge in the left part of the window.\n",
    "        \"\"\"\n",
    "        # Flatten the window by calculating max value among all sensors\n",
    "        window_data = np.max(window_data, axis = 1)\n",
    "        # convolution for edge detection\n",
    "        _filter = np.array([-1, 1])\n",
    "        edge = np.convolve(window_data, _filter, 'valid')\n",
    "        half_window_len = int((len(window_data) - 1) / 2)\n",
    "        left_edge_height = np.max(edge[:half_window_len])\n",
    "        right_edge_height = np.max(edge[half_window_len:])\n",
    "        return (left_edge_height, right_edge_height)\n",
    "    \n",
    "    def summarize_window(window_data):\n",
    "        if nrt_type == \"sum\":\n",
    "            return np.count_nonzero(window_data, axis=0)\n",
    "        elif nrt_type == \"max\":\n",
    "            return np.max(window_data, axis = 0)\n",
    "        elif nrt_type == \"instantaneous\":\n",
    "            center = int((window_data.shape[0] - 1) / 2)\n",
    "            return window_data[center]\n",
    "\n",
    "    # Initialize the output array\n",
    "    sensor_num = mat.shape[1]\n",
    "    last_fired_time = np.full((sensor_num,), -1)\n",
    "    last_fired_sensors = np.zeros(sensor_num, dtype = bool)\n",
    "    \n",
    "    w = int((window_len - 1)/2)\n",
    "    window_data = np.zeros((window_len, sensor_num))\n",
    "\n",
    "    for i in range(w):\n",
    "        sd = mat[i]\n",
    "        if np.any(sd):\n",
    "            for s in range(sensor_num):\n",
    "                if not last_fired_sensors[s] and sd[s]:\n",
    "                    last_fired_time[s] = i\n",
    "                if last_fired_sensors[s] and not sd[s]:\n",
    "                    last_fired_time[s] = -1\n",
    "            last_fired_sensors = sd\n",
    "\n",
    "        instantaneous_nrt = np.empty(sensor_num)\n",
    "        for s in range(sensor_num):\n",
    "            instantaneous_nrt[s] = ((i - last_fired_time[s] + 1) if last_fired_time[s] != -1 else 0)\n",
    "        window_data[i+w+1, :] = instantaneous_nrt\n",
    "\n",
    "    # [0, 0, 0, a, b] for example of w = 2.\n",
    "\n",
    "    for i in range(w, mat.shape[0]):\n",
    "        utils.print_progress_bar(mat.shape[0] - 1, i, \"Extract fall features.\", step = 1000)\n",
    "        # center = i - w  # index of window center\n",
    "        sd = mat[i]\n",
    "        if np.any(sd):\n",
    "            for s in range(sensor_num):\n",
    "                if not last_fired_sensors[s] and sd[s]:\n",
    "                    last_fired_time[s] = i\n",
    "                if last_fired_sensors[s] and not sd[s]:\n",
    "                    last_fired_time[s] = -1\n",
    "            last_fired_sensors = sd\n",
    "\n",
    "        instantaneous_nrt = np.empty(sensor_num)\n",
    "        for s in range(sensor_num):\n",
    "            instantaneous_nrt[s] = ((i - last_fired_time[s] + 1) if last_fired_time[s] != -1 else 0)\n",
    "\n",
    "        # shift window\n",
    "        # For example of w = 2;\n",
    "        # from [a, b, c, d, e] to [b, c, d, e, f]\n",
    "        window_data = np.roll(window_data, shift=-1, axis=0)\n",
    "        window_data[-1, :] = instantaneous_nrt\n",
    "\n",
    "        # Calculate elapsed time of the sliding window\n",
    "        yield summarize_window(window_data) * time_step\n",
    "\n",
    "    for center in range(mat.shape[0]-w, mat.shape[0]):\n",
    "         # shift window\n",
    "        window_data = np.roll(window_data, shift=-1, axis=0)\n",
    "        window_data[-1, :] = np.zeros(sensor_num)\n",
    "\n",
    "        # Calculate elapsed time of the sliding window\n",
    "        yield summarize_window(window_data) * time_step\n",
    "\n",
    "def extract_data_with_fall_feature_sliding(path, data_type = \"raw\", time_step = 1, window_len = 121, nrt_type = \"instantaneous\", data_range = \"full\", half_len = 10000):\n",
    "    if data_range not in [\"full\", \"around_anomalies\"]:\n",
    "        raise ValueError(\"data_range is invalid value!\")\n",
    "    \n",
    "    SD_model = utils.pickle_load(path, \"SD_model\")\n",
    "    # SD = utils.pickle_load(path / \"experiment\", f\"reduced_301_SD_mat_{data_type}_1\")\n",
    "    SD = utils.pickle_load(path / \"experiment\", f\"SD_mat_raw_5\")    # !!!!!!!!!!!!!!!!!!!!\n",
    "    AL = utils.pickle_load(path / \"experiment\", f\"AL_mat_raw_5\")\n",
    "    SD_names = utils.pickle_load(path / \"experiment\", \"SD_names\")\n",
    "\n",
    "    SD = SD[:, [i for i in range(SD.shape[1]) if i != 6]]\n",
    "\n",
    "    # extract motion sensor data\n",
    "    motion_sensor_indexes = []\n",
    "    for i, s_i in enumerate(SD_names):\n",
    "        if SD_model[s_i].type_name in ['PIR', 'pressure', 'door']:\n",
    "            motion_sensor_indexes.append(i)\n",
    "    SD = SD[:, motion_sensor_indexes]\n",
    "\n",
    "    # extract fall labels\n",
    "    anomaly_index = 4\n",
    "    AL = AL[:, anomaly_index]\n",
    "    \n",
    "    # extract features of non response time\n",
    "    if data_range == \"full\":\n",
    "        X = fall_feature_sliding(SD, time_step=time_step, window_len=window_len, nrt_type=nrt_type)\n",
    "        return X, AL, motion_sensor_indexes\n",
    "    elif data_range == \"around_anomalies\":\n",
    "        fall_indices = analysis.find_true_regions_in_ndarray(AL)\n",
    "        X = np.empty((0, len(motion_sensor_indexes)))\n",
    "        y = []\n",
    "        for r in fall_indices:\n",
    "            start, end = r[0] - half_len, r[1] + half_len\n",
    "            if (start < 0) or (SD.shape[0] < end):\n",
    "                continue\n",
    "            feature = fall_feature_sliding(SD[start:end], time_step=time_step, window_len=window_len, nrt_type=nrt_type)\n",
    "            X = np.vstack((X, feature))\n",
    "            for i in range(start, end):\n",
    "                y.append(True in [r[0] <= i < r[1] for r in fall_indices])\n",
    "        return X, np.array(y), motion_sensor_indexes\n",
    "    \n",
    "    \n",
    "def online_detection_test(classifier, path, data_type = \"raw\", time_step = 1, window_len = 121, nrt_type = \"instantaneous\", data_range = \"full\", half_len = 10000):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (y_true, y_pred) : tuple of numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if (data_range not in [\"full\", \"around_anomalies\"]) and not isinstance(data_range, tuple):\n",
    "        raise ValueError(\"data_range is invalid value!\")\n",
    "    \n",
    "    SD_model = utils.pickle_load(path, \"SD_model\")\n",
    "    # SD = utils.pickle_load(path / \"experiment\", f\"reduced_301_SD_mat_{data_type}_{time_step}\")\n",
    "    SD = utils.pickle_load(path / \"experiment\", f\"SD_mat_{data_type}_{time_step}\")\n",
    "    AL = utils.pickle_load(path / \"experiment\", f\"AL_mat_{data_type}_{time_step}\")\n",
    "    SD_names = utils.pickle_load(path / \"experiment\", \"SD_names\")\n",
    "\n",
    "    SD = SD[:, [i for i in range(SD.shape[1]) if i != 6]]\n",
    "\n",
    "    # extract motion sensor data\n",
    "    motion_sensor_indexes = []\n",
    "    for i, s_i in enumerate(SD_names):\n",
    "        if SD_model[s_i].type_name in ['PIR', 'pressure', 'door']:\n",
    "            motion_sensor_indexes.append(i)\n",
    "    SD = SD[:, motion_sensor_indexes]\n",
    "\n",
    "    # extract fall labels\n",
    "    anomaly_index = 4\n",
    "    AL = AL[:, anomaly_index]\n",
    "\n",
    "    # extract features of non response time\n",
    "    if data_range == \"full\":\n",
    "        y_pred = np.zeros(SD.shape[0], dtype = bool)\n",
    "        for i, item in enumerate(gen_fall_feature_sliding(SD, time_step, window_len, nrt_type)):\n",
    "            y_pred[i] = classifier.predict(item.reshape(1, -1))\n",
    "        return AL, y_pred\n",
    "    elif data_range == \"around_anomalies\":\n",
    "        fall_indices = analysis.find_true_regions_in_ndarray(AL)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for r in fall_indices:\n",
    "            start, end = r[0] - half_len, r[1] + half_len\n",
    "            if (start < 0) or (SD.shape[0] < end):\n",
    "                continue\n",
    "            for i, item in enumerate(gen_fall_feature_sliding(SD[start:end], time_step, window_len, nrt_type)):\n",
    "                y_pred.append(classifier.predict(item.reshape(1, -1)))\n",
    "            for i in range(start, end):\n",
    "                y_true.append(True in [r[0] <= i < r[1] for r in fall_indices])\n",
    "        return y_true, y_pred\n",
    "    elif isinstance(data_range, tuple):\n",
    "        start, end = data_range[0], data_range[1]\n",
    "        y_pred = np.zeros(end-start, dtype = bool)\n",
    "        for i, item in enumerate(gen_fall_feature_sliding(SD[start:end], time_step, window_len, nrt_type)):\n",
    "            y_pred[i] = classifier.predict(item.reshape(1, -1))\n",
    "        return AL[start:end], y_pred\n",
    "\n",
    "\n",
    "def online_detection_rule(path, data_type = \"raw\", time_step = 1, window_len = 121, nrt_type = \"instantaneous\", data_range = \"full\", half_len = 10000):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (y_true, y_pred) : tuple of numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def classifier_rule(vec, valid_range):\n",
    "        for i, v in enumerate(vec):\n",
    "            if (i in valid_range) and v >= 20:\n",
    "                return True\n",
    "        else:\n",
    "            False    \n",
    "    \n",
    "    if (data_range not in [\"full\", \"around_anomalies\"]) and not isinstance(data_range, tuple):\n",
    "        raise ValueError(\"data_range is invalid value!\")\n",
    "    \n",
    "    SD_model = utils.pickle_load(path, \"SD_model\")\n",
    "    # SD = utils.pickle_load(path / \"experiment\", f\"reduced_301_SD_mat_{data_type}_{time_step}\")\n",
    "    SD = utils.pickle_load(path / \"experiment\", f\"SD_mat_{data_type}_{time_step}\")\n",
    "    AL = utils.pickle_load(path / \"experiment\", f\"AL_mat_{data_type}_{time_step}\")\n",
    "    SD_names = utils.pickle_load(path / \"experiment\", \"SD_names\")\n",
    "\n",
    "    # extract motion sensor data\n",
    "    motion_sensor_indexes = []\n",
    "    for i, s_i in enumerate(SD_names):\n",
    "        if SD_model[s_i].type_name in ['PIR', 'pressure', 'door']:\n",
    "            motion_sensor_indexes.append(i)\n",
    "    SD = SD[:, motion_sensor_indexes]\n",
    "\n",
    "    # extract fall labels\n",
    "    anomaly_index = 4\n",
    "    AL = AL[:, anomaly_index]\n",
    "\n",
    "    valid_range = set(range(0, 22)) + {33, 34} \n",
    "\n",
    "    # extract features of non response time\n",
    "    if data_range == \"full\":\n",
    "        y_pred = np.zeros(SD.shape[0], dtype = bool)\n",
    "        for i, item in enumerate(gen_fall_feature_sliding(SD, time_step, window_len, nrt_type)):\n",
    "            y_pred[i] = classifier_rule(item, valid_range)\n",
    "        return AL, y_pred\n",
    "    elif data_range == \"around_anomalies\":\n",
    "        fall_indices = analysis.find_true_regions_in_ndarray(AL)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for r in fall_indices:\n",
    "            start, end = r[0] - half_len, r[1] + half_len\n",
    "            if (start < 0) or (SD.shape[0] < end):\n",
    "                continue\n",
    "            for i, item in enumerate(gen_fall_feature_sliding(SD[start:end], time_step, window_len, nrt_type)):\n",
    "                y_pred.append(classifier_rule(item, valid_range))\n",
    "            for i in range(start, end):\n",
    "                y_true.append(True in [r[0] <= i < r[1] for r in fall_indices])\n",
    "        return y_true, y_pred\n",
    "    elif isinstance(data_range, tuple):\n",
    "        start, end = data_range[0], data_range[1]\n",
    "        y_pred = np.zeros(end-start, dtype = bool)\n",
    "        for i, item in enumerate(gen_fall_feature_sliding(SD[start:end], time_step, window_len, nrt_type)):\n",
    "            y_pred[i] = classifier_rule(item, valid_range)\n",
    "        return AL[start:end], y_pred\n",
    "\n",
    "data_type = \"raw\"\n",
    "time_step = 1\n",
    "window_len = 121\n",
    "# half_len = 5000\n",
    "half_len = 30000\n",
    "nrt_type = \"instantaneous\"\n",
    "\n",
    "# training data\n",
    "# train_path = layout_database_path / \"test_layout\" / \"test_data_3\"\n",
    "# X_train, y_train, motion_sensor_indexes  = extract_data_with_fall_feature_sliding(train_path, \n",
    "#         data_type = data_type, time_step = time_step, window_len = window_len, nrt_type = nrt_type, data_range = \"around_anomalies\", half_len = half_len)\n",
    "\n",
    "train_path = layout_database_path / \"test_layout\" / \"fall_test_2\"\n",
    "X_train, y_train, motion_sensor_indexes  = extract_data_with_fall_feature_sliding(train_path, \n",
    "        data_type = data_type, time_step = time_step, window_len = window_len, nrt_type = nrt_type, data_range = \"full\", half_len = half_len)\n",
    "print(\"Training data is ready!\")\n",
    "\n",
    "# decision tree\n",
    "decision_tree = DecisionTreeClassifier(min_samples_leaf=5)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "print(\"Classifier is ready!\")\n",
    "\n",
    "# test data\n",
    "test_path = layout_database_path / \"test_layout\" / \"test_data_5\"\n",
    "\n",
    "# classfy after generating test data\n",
    "# X_test, y_true, motion_sensor_indexes = extract_data_with_fall_feature_sliding(test_path,\n",
    "#         data_type = data_type, time_step=time_step, window_len=window_len, nrt_type = nrt_type, data_range = \"around_anomalies\", half_len = half_len)\n",
    "# print(\"Test data is ready!\")\n",
    "# y_test_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# y_test, y_pred = online_detection_test(decision_tree, test_path,\n",
    "#         data_type = data_type, time_step=time_step, window_len=window_len, nrt_type = nrt_type, data_range = \"around_anomalies\", half_len = half_len)\n",
    "\n",
    "# y_pred = decision_tree.predict(X_train)\n",
    "# print(\"Training error ------------------------\")\n",
    "# print(\"Confusion matrix:\")\n",
    "# print(confusion_matrix(y_train, y_pred))\n",
    "# print(\"Classification report\")\n",
    "# print(classification_report(y_train, y_pred))\n",
    "\n",
    "# print(\"Test error ------------------------\")\n",
    "# print(\"Confusion matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(\"Classification report\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 9*360*24*60*60\n",
    "start = end - 3*30*24*60*60\n",
    "test_path = layout_database_path / \"test_layout\" / \"test_data_5\"\n",
    "y_test_r, y_pred_r = online_detection_rule(test_path,\n",
    "        data_type = data_type, time_step=time_step, window_len=window_len, nrt_type = nrt_type, data_range = (start, end), half_len = half_len)\n",
    "\n",
    "y_test_d, y_pred_d = online_detection_test(decision_tree, test_path,\n",
    "        data_type = data_type, time_step=time_step, window_len=window_len, nrt_type = nrt_type, data_range = (start, end), half_len = half_len)\n",
    "\n",
    "# y_pred = decision_tree.predict(X_train)\n",
    "# print(\"Training error ------------------------\")\n",
    "# print(\"Confusion matrix:\")\n",
    "# print(confusion_matrix(y_train, y_pred))\n",
    "# print(\"Classification report\")\n",
    "# print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Test error Rule------------------------\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_r, y_pred_r))\n",
    "print(\"Classification report\")\n",
    "print(classification_report(y_test_r, y_pred_r))\n",
    "\n",
    "\n",
    "print(\"Test error DT------------------------\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_d, y_pred_d))\n",
    "print(\"Classification report\")\n",
    "print(classification_report(y_test_d, y_pred_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
