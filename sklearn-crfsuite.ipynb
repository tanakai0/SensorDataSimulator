{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "still-midnight",
   "metadata": {},
   "source": [
    "# sklearn-crfsuite\n",
    "\n",
    "Memo\n",
    "- [sklearn-crfsuite の公式 Tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)\n",
    "- [Tutorial の IPython file](https://github.com/TeamHG-Memex/sklearn-crfsuite/blob/master/docs/CoNLL2002.ipynb)\n",
    "- [入力データの内部形式](https://python-crfsuite.readthedocs.io/en/latest/pycrfsuite.html) \n",
    "- [CRFモデルで時系列データからある時点の状態を推定する](https://qiita.com/ruka38/items/c9212d827acfdd9d41a7)\n",
    "- AttributeError: 'CRF' object has no attribute 'keep_tempfiles' の発生 -> sklearn_crfsuite.\\_\\_file\\_\\_ で表示されたパスにあるファイルを[このバグ報告](https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/60)のdoctor-entropy のコメントの通りに修正する\n",
    "- 上のエラーを[直したバージョン](https://github.com/TeamHG-Memex/sklearn-crfsuite/blob/master/docs/CoNLL2002.ipynb)もあるらしいけどうまくできなかった\n",
    "- [pycrfsuite の Cython ファイル](https://github.com/scrapinghub/python-crfsuite/blob/master/pycrfsuite/_pycrfsuite.pyx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b6efc-bad6-4482-83f6-9e36982d3870",
   "metadata": {},
   "source": [
    "# Example: Conll2002 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hungarian-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\tanakai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']\n",
      "{'bias': 1.0, 'word.lower()': 'melbourne', 'word[-3:]': 'rne', 'word[-2:]': 'ne', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'NP', 'postag[:2]': 'NP', 'BOS': True, '+1:word.lower()': '(', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'Fpa', '+1:postag[:2]': 'Fp'}\n",
      "['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "nltk.download('conll2002')\n",
    "print(nltk.corpus.conll2002.fileids())\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "print(X_train[0][0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qualified-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "integrated-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-ORG', 'I-LOC', 'I-MISC']\n",
      "0.7964686316443963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.810     0.784     0.797      1084\n",
      "       I-LOC      0.690     0.637     0.662       325\n",
      "      B-MISC      0.731     0.569     0.640       339\n",
      "      I-MISC      0.699     0.589     0.639       557\n",
      "       B-ORG      0.807     0.832     0.820      1400\n",
      "       I-ORG      0.852     0.786     0.818      1104\n",
      "       B-PER      0.850     0.884     0.867       735\n",
      "       I-PER      0.893     0.943     0.917       634\n",
      "\n",
      "   micro avg      0.813     0.787     0.799      6178\n",
      "   macro avg      0.791     0.753     0.770      6178\n",
      "weighted avg      0.809     0.787     0.796      6178\n",
      "\n",
      "Top likely transitions:\n",
      "B-ORG  -> I-ORG   7.500912\n",
      "I-ORG  -> I-ORG   7.206322\n",
      "B-MISC -> I-MISC  6.833142\n",
      "I-MISC -> I-MISC  6.753222\n",
      "B-PER  -> I-PER   6.404557\n",
      "B-LOC  -> I-LOC   5.696274\n",
      "I-LOC  -> I-LOC   4.877422\n",
      "I-PER  -> I-PER   4.709231\n",
      "O      -> O       3.784430\n",
      "O      -> B-ORG   2.754974\n",
      "O      -> B-PER   2.549453\n",
      "O      -> B-LOC   1.846099\n",
      "O      -> B-MISC  1.804584\n",
      "B-LOC  -> B-LOC   0.578393\n",
      "B-ORG  -> O       0.325175\n",
      "I-PER  -> B-LOC   0.300667\n",
      "B-MISC -> B-ORG   0.298525\n",
      "B-ORG  -> B-LOC   0.266688\n",
      "B-LOC  -> B-PER   -0.046324\n",
      "B-MISC -> O       -0.143646\n",
      "Top unlikely transitions:\n",
      "I-LOC  -> B-MISC  -1.976574\n",
      "I-MISC -> I-PER   -2.008671\n",
      "B-ORG  -> B-ORG   -2.107974\n",
      "I-ORG  -> B-LOC   -2.199630\n",
      "I-MISC -> B-LOC   -2.240108\n",
      "I-ORG  -> I-PER   -2.272384\n",
      "B-PER  -> B-MISC  -2.325289\n",
      "I-PER  -> I-LOC   -2.455352\n",
      "I-ORG  -> B-MISC  -2.486495\n",
      "I-PER  -> B-ORG   -2.512129\n",
      "I-ORG  -> I-LOC   -2.536158\n",
      "I-MISC -> I-LOC   -2.557052\n",
      "B-ORG  -> B-MISC  -2.581202\n",
      "B-PER  -> B-PER   -2.825385\n",
      "I-PER  -> B-MISC  -2.966281\n",
      "B-MISC -> B-MISC  -3.028264\n",
      "O      -> I-MISC  -5.136612\n",
      "O      -> I-ORG   -5.230042\n",
      "O      -> I-PER   -5.357097\n",
      "O      -> I-LOC   -5.968293\n",
      "Top positive:\n",
      "9.810583 B-ORG    word.lower():efe-cantabria\n",
      "8.587255 B-ORG    word.lower():psoe-progresistas\n",
      "6.026318 I-ORG    -1:word.lower():l\n",
      "4.902771 B-ORG    word.lower():xfera\n",
      "4.896558 B-LOC    -1:word.lower():cantabria\n",
      "4.867565 O        BOS\n",
      "4.810829 B-LOC    word.lower():líbano\n",
      "4.760313 B-ORG    word.lower():telefónica\n",
      "4.723549 B-MISC   word.lower():justicia\n",
      "4.674730 B-ORG    word[-2:]:-e\n",
      "4.597672 B-MISC   word.lower():competencia\n",
      "4.582394 O        word.lower():r.\n",
      "4.582394 O        word[-3:]:R.\n",
      "4.545455 B-MISC   word.lower():diversia\n",
      "4.409233 B-ORG    word.lower():petrobras\n",
      "4.277603 B-ORG    word.lower():coag-extremadura\n",
      "4.261705 B-PER    -1:word.lower():según\n",
      "4.229368 I-LOC    -1:word.lower():calle\n",
      "4.223481 B-ORG    word.isupper()\n",
      "4.189817 B-ORG    word.lower():esquerra\n",
      "4.188726 B-PER    word.lower():valedor\n",
      "4.156011 O        word.lower():b\n",
      "4.156011 O        word[-3:]:B\n",
      "4.156011 O        word[-2:]:B\n",
      "4.150794 B-ORG    word.lower():terra\n",
      "4.121745 B-ORG    -1:word.lower():distancia\n",
      "4.063192 B-LOC    -1:word.lower():celebrarán\n",
      "4.043389 I-ORG    -1:word.lower():rasd\n",
      "4.017850 B-ORG    +1:word.lower():plasencia\n",
      "3.944671 B-MISC   word.lower():exteriores\n",
      "Top negative:\n",
      "-1.934899 B-MISC   word.lower():tribunal\n",
      "-1.941387 B-LOC    word[-3:]:ión\n",
      "-1.998870 O        postag:NP\n",
      "-1.998870 O        postag[:2]:NP\n",
      "-1.999583 B-PER    word[-2:]:os\n",
      "-2.005460 B-PER    word[-2:]:ón\n",
      "-2.040716 B-LOC    word[-3:]:la\n",
      "-2.043386 I-LOC    BOS\n",
      "-2.056432 O        -1:word.lower():agora\n",
      "-2.076812 I-PER    +1:word.lower():el\n",
      "-2.125426 O        -1:word.lower():británica\n",
      "-2.136499 O        +1:word.lower():justicia\n",
      "-2.170635 O        word.lower():061\n",
      "-2.183942 I-PER    +1:word.lower():del\n",
      "-2.189562 B-MISC   -1:word.isupper()\n",
      "-2.389167 O        word[-3:]:bas\n",
      "-2.421343 B-PER    word[-3:]:nes\n",
      "-2.423597 O        +1:word.lower():plasencia\n",
      "-2.425600 O        -1:word.lower():sección\n",
      "-2.426862 O        word[-2:]:nd\n",
      "-2.456323 O        word[-3:]:730\n",
      "-2.706624 O        word[-3:]:LOS\n",
      "-3.051235 O        word.lower():mas\n",
      "-3.053493 O        -1:word.lower():españolas\n",
      "-3.229068 I-PER    -1:word.lower():san\n",
      "-3.444361 B-PER    -1:word.lower():del\n",
      "-3.911123 O        -1:word.lower():celebrarán\n",
      "-4.310235 O        word[-2:]:om\n",
      "-5.999096 O        word.isupper()\n",
      "-8.285736 O        word.istitle()\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(labels)\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))\n",
    "\n",
    "# details\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "from sklearn.metrics import classification_report\n",
    "# This code has not been worked.\n",
    "# print(metrics.flat_classification_report(\n",
    "#     y_test, y_pred, labels=sorted_labels, digits=3\n",
    "# ))\n",
    "print(classification_report(\n",
    "    list(chain.from_iterable(y_test)), list(chain.from_iterable(y_pred)), labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "        \n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "print(\"Top unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "print(\"Top negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888dfbf-1d4b-4f42-aa67-6d36055e3ac9",
   "metadata": {},
   "source": [
    "# sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99db93c-f453-456e-b55e-e762a0f2977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "import scipy.stats\n",
    "from pathlib import Path\n",
    "from sklearn_crfsuite import scorers, metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# self-made\n",
    "import activity_model\n",
    "import analysis\n",
    "import anomaly\n",
    "import comparison\n",
    "import floor_plan\n",
    "\n",
    "import new_functions\n",
    "import sensor_model\n",
    "\n",
    "working_path = Path().resolve()\n",
    "layout_data_path = working_path / 'layout_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b72ad-bf34-48ad-8f3a-fbbbc24a02fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wandering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d154a0-56d5-4da4-8e02-241a80d1193d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data2features(data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        data.shape = (number of time, number of sensors).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : list of dict\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    T = data.shape[0]  # number of time\n",
    "    M = data.shape[1]  # number of sensors\n",
    "    for i in range(T):\n",
    "        d = data[i]\n",
    "        feature = {f\"x_{j}\": d[j] for j in range(M)}\n",
    "        # if i >= 1:\n",
    "        #     feature.update({f\"-1 x_{j}\": data[i-1][j] for j in range(M)})\n",
    "        # if i >= 60:\n",
    "        #     feature['sum_60'] = np.sum(data[i-60:i])\n",
    "        if i == 0:\n",
    "            feature['BOS'] = True\n",
    "        if i == T - 1:\n",
    "            feature['EOS'] = True\n",
    "        feature['bias'] = 1\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "_type = 'raw'\n",
    "data_folder_name = 'test_data_1'\n",
    "path = layout_data_path / 'test_layout' / data_folder_name\n",
    "reduced_SD_mat = new_functions.pickle_load(path / 'experiment1', f'reduced_SD_mat_{_type}_1')\n",
    "reduced_AL_mat = new_functions.pickle_load(path / 'experiment1', f'reduced_AL_mat_{_type}_1')\n",
    "SD_names = new_functions.pickle_load(path / 'experiment1', 'SD_names')\n",
    "AL_names = new_functions.pickle_load(path / 'experiment1', 'AL_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f626bbe-c27b-45f8-82d9-b2f53df90084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13011\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "# X_train = [[{'a': True, 'b':1.2}, {'a': False, 'b':2}]]\n",
    "# y_train = [['True', 'False']]\n",
    "\n",
    "start = len(reduced_SD_mat) - 3000000\n",
    "end = len(reduced_SD_mat)\n",
    "\n",
    "X_train = [data2features(reduced_SD_mat[start:end, :24])]\n",
    "y_train = [[str(b) for b in reduced_AL_mat[start:end, 3]]]\n",
    "print(np.sum(reduced_AL_mat[start:end, 3]))\n",
    "\n",
    "c1, c2 = 0.1, 0.1\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm = 'lbfgs', \n",
    "    c1 = c1, \n",
    "    c2 = c2, \n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "new_functions.pickle_dump(path / 'experiment1', f\"crf_c1_{c1}_c2_{c2}\", crf)\n",
    "# test = new_functions.pickle_load(path / 'experiment1', f\"crf_c1_{c1}_c2_{c2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dc6872-fb6c-494f-906b-9ec0b105dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['False', 'True']\n",
      "0.9998835758709718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      1.000     1.000     1.000   2987360\n",
      "        True      0.982     0.990     0.986     12640\n",
      "\n",
      "    accuracy                          1.000   3000000\n",
      "   macro avg      0.991     0.995     0.993   3000000\n",
      "weighted avg      1.000     1.000     1.000   3000000\n",
      "\n",
      "transition features:\n",
      "False  -> False   2.133736\n",
      "True   -> True    1.310936\n",
      "False  -> True    -7.315851\n",
      "True   -> False   -7.315851\n",
      "state features:\n",
      "0.897318 True     x_16\n",
      "0.840242 True     x_1\n",
      "0.810025 True     x_6\n",
      "0.788247 True     x_0\n",
      "0.612350 True     x_21\n",
      "0.576940 True     x_17\n",
      "0.515215 True     x_22\n",
      "0.496369 True     x_15\n",
      "0.481397 True     x_12\n",
      "0.479434 True     x_4\n",
      "0.476213 True     x_18\n",
      "0.458880 True     x_9\n",
      "0.428461 True     x_20\n",
      "0.369071 True     x_5\n",
      "0.339902 True     x_19\n",
      "0.323552 False    x_10\n",
      "0.287443 True     x_3\n",
      "0.284892 True     x_2\n",
      "0.227538 True     x_23\n",
      "0.217543 True     x_11\n",
      "0.194568 True     x_13\n",
      "0.193750 True     x_14\n",
      "0.182578 True     x_8\n",
      "0.143415 False    x_7\n",
      "0.026463 False    bias\n",
      "-0.026458 True     bias\n",
      "-0.143415 True     x_7\n",
      "-0.182578 False    x_8\n",
      "-0.193750 False    x_14\n",
      "-0.194568 False    x_13\n",
      "-0.217543 False    x_11\n",
      "-0.227538 False    x_23\n",
      "-0.284892 False    x_2\n",
      "-0.287443 False    x_3\n",
      "-0.323552 True     x_10\n",
      "-0.339902 False    x_19\n",
      "-0.369071 False    x_5\n",
      "-0.428461 False    x_20\n",
      "-0.458880 False    x_9\n",
      "-0.476213 False    x_18\n",
      "-0.479434 False    x_4\n",
      "-0.481397 False    x_12\n",
      "-0.496369 False    x_15\n",
      "-0.515215 False    x_22\n",
      "-0.576940 False    x_17\n",
      "-0.612350 False    x_21\n",
      "-0.788247 False    x_0\n",
      "-0.810025 False    x_6\n",
      "-0.840242 False    x_1\n",
      "-0.897318 False    x_16\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluation\n",
    "_type = 'raw'\n",
    "data_folder_name = 'test_data_2'\n",
    "path = layout_data_path / 'test_layout' / data_folder_name\n",
    "test_SD = new_functions.pickle_load(path / 'experiment1', f'reduced_SD_mat_{_type}_1')\n",
    "test_AL = new_functions.pickle_load(path / 'experiment1', f'reduced_AL_mat_{_type}_1')\n",
    "test_SD_names = new_functions.pickle_load(path / 'experiment1', 'SD_names')\n",
    "test_AL_names = new_functions.pickle_load(path / 'experiment1', 'AL_names')\n",
    "\n",
    "X_test = [data2features(test_SD[start:end, :24])]\n",
    "y_test = [[str(b) for b in test_AL[start:end, 3]]]\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "print(labels)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))\n",
    "\n",
    "# details\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "print(classification_report(\n",
    "    list(chain.from_iterable(y_test)), list(chain.from_iterable(y_pred)), labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "        \n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"transition features:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common())\n",
    "\n",
    "print(\"state features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2a73f-548b-4b69-a125-c27298d5b6cc",
   "metadata": {},
   "source": [
    "# Falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ccab3ac-fb04-4e96-a0e9-3d240ed38891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['being semi-bedridden', 'being housebound', 'forgetting', 'wandering', 'fall while walking', 'fall while standing']\n",
      "(72722821, 28)\n",
      "(72722821, 6)\n",
      "786\n"
     ]
    }
   ],
   "source": [
    "def data2features(data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        data.shape = (number of time, number of sensors).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : list of dict\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    T = data.shape[0]  # number of time\n",
    "    M = data.shape[1]  # number of sensors\n",
    "    for i in range(T):\n",
    "        d = data[i]\n",
    "        feature = {f\"x_{j}\": d[j] for j in range(M)}\n",
    "        # if i >= 1:\n",
    "        #     feature.update({f\"-1 x_{j}\": data[i-1][j] for j in range(M)})\n",
    "        if i >= 60:\n",
    "            feature['sum_60'] = np.sum(data[i-60:i])\n",
    "        if i == 0:\n",
    "            feature['BOS'] = True\n",
    "        if i == T - 1:\n",
    "            feature['EOS'] = True\n",
    "        feature['bias'] = 1\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "_type = 'raw'\n",
    "data_folder_name = 'test_data_1'\n",
    "path = layout_data_path / 'test_layout' / data_folder_name\n",
    "reduced_SD_mat = new_functions.pickle_load(path / 'experiment1', f'reduced_SD_mat_{_type}_1')\n",
    "reduced_AL_mat = new_functions.pickle_load(path / 'experiment1', f'reduced_AL_mat_{_type}_1')\n",
    "SD_names = new_functions.pickle_load(path / 'experiment1', 'SD_names')\n",
    "AL_names = new_functions.pickle_load(path / 'experiment1', 'AL_names')\n",
    "anomaly_index = 5\n",
    "print(AL_names)\n",
    "print(reduced_SD_mat.shape)\n",
    "print(reduced_AL_mat.shape)\n",
    "print(np.sum(reduced_AL_mat[:, anomaly_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73effa79-340a-4b0b-b2af-f82445d3aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(758857, 758875), (2616596, 2616633), (6209812, 6209838), (8580415, 8580444), (9169741, 9169765), (16853411, 16853446), (26196152, 26196174), (29074204, 29074226), (30813595, 30813625), (33184887, 33184913), (34073814, 34073855), (37756467, 37756495), (37812288, 37812316), (41626770, 41626803), (41945309, 41945347), (41977680, 41977702), (49674922, 49674945), (54236540, 54236569), (57900850, 57900880), (59147803, 59147849), (59439139, 59439175), (61108304, 61108336), (63087143, 63087174), (66417543, 66417582), (69896349, 69896383), (72701854, 72701881)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_true_regions(arr):\n",
    "    \"\"\"\n",
    "    Find continuous True regions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy.ndarray\n",
    "        arr.shape = (n, ).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    start_end_indices : list of tuple of int\n",
    "        start_end_indices[i] = (index of start, index of end) of ith regions.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> find_true_regions(np.array([False, True, True, False, False, True, True, True, False, True]))\n",
    "    >>> [(1, 3), (5, 8), (9, 10)]\n",
    "    \"\"\"\n",
    "    indices = np.where(arr)[0]\n",
    "    split_points = np.where(np.diff(indices) > 1)[0] + 1\n",
    "    ranges = np.split(indices, split_points)\n",
    "    start_end_indices = [(r[0], r[-1] + 1) for r in ranges]\n",
    "    return start_end_indices\n",
    "\n",
    "fall_w_indices = find_true_regions(reduced_AL_mat[:, anomaly_index])\n",
    "print(fall_w_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "154453d0-024d-47ca-8862-6b0888f8c9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "# X_train = [[{'a': True, 'b':1.2}, {'a': False, 'b':2}]]\n",
    "# y_train = [['True', 'False']]\n",
    "\n",
    "half_len = 100000\n",
    "data_indices = [(r[0] - half_len, r[1] + half_len) for r in fall_w_indices]\n",
    "X_train = [data2features(reduced_SD_mat[r[0]:r[1], :24]) for r in data_indices]\n",
    "y_train = [[str(b) for b in reduced_AL_mat[r[0]:r[1], anomaly_index]] for r in data_indices]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm = 'lbfgs', \n",
    "    c1 = 0.1, \n",
    "    c2 = 0.1, \n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "940a6167-1994-420a-9037-5d6a375a8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(490810, 490831), (1336048, 1336087), (3846561, 3846598), (5726091, 5726115), (7264576, 7264612), (8467347, 8467376), (8637608, 8637629), (12273516, 12273542), (12415247, 12415279), (12947694, 12947728), (14687685, 14687707), (15938852, 15938877), (16378152, 16378184), (17209211, 17209235), (17336877, 17336904), (26007867, 26007905), (27090838, 27090865), (30423831, 30423859), (31546022, 31546049), (32037386, 32037407), (32684648, 32684680), (35247375, 35247410), (35675941, 35675968), (37134881, 37134912), (37644872, 37644899), (38288556, 38288586), (38353858, 38353886), (40288372, 40288404), (40885306, 40885350), (42196073, 42196109), (42283292, 42283328), (42575656, 42575680), (45375260, 45375292), (47692682, 47692726), (47731128, 47731166), (50295690, 50295721), (50825838, 50825871), (51701206, 51701243), (54899686, 54899723), (55245380, 55245406), (56026406, 56026438), (58011056, 58011085), (58204875, 58204908), (62549513, 62549546), (66668902, 66668929), (69690030, 69690058), (70516246, 70516281), (73759531, 73759553)]\n",
      "['False', 'True']\n",
      "0.9999996874083069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      1.000     1.000     1.000   9599788\n",
      "        True      1.000     0.998     0.999      1681\n",
      "\n",
      "    accuracy                          1.000   9601469\n",
      "   macro avg      1.000     0.999     1.000   9601469\n",
      "weighted avg      1.000     1.000     1.000   9601469\n",
      "\n",
      "transition features:\n",
      "False  -> False   3.762994\n",
      "True   -> True    1.311364\n",
      "False  -> True    -4.045224\n",
      "True   -> False   -4.045616\n",
      "state features:\n",
      "3.332335 True     x_22\n",
      "2.758222 False    x_2\n",
      "1.511983 False    x_6\n",
      "1.269903 False    x_11\n",
      "0.810702 False    x_23\n",
      "0.338645 False    bias\n",
      "0.018151 False    sum_60\n",
      "-0.018150 True     sum_60\n",
      "-0.338343 True     bias\n",
      "-0.810702 True     x_23\n",
      "-1.269903 True     x_11\n",
      "-1.511983 True     x_6\n",
      "-2.758222 True     x_2\n",
      "-3.332335 False    x_22\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluation\n",
    "_type = 'raw'\n",
    "data_folder_name = 'test_data_2'\n",
    "path = layout_data_path / 'test_layout' / data_folder_name\n",
    "test_SD = new_functions.pickle_load(path / 'experiment1', f'reduced_SD_mat_{_type}_1')\n",
    "test_AL = new_functions.pickle_load(path / 'experiment1', f'reduced_AL_mat_{_type}_1')\n",
    "test_SD_names = new_functions.pickle_load(path / f'experiment1', 'SD_names')\n",
    "test_AL_names = new_functions.pickle_load(path / 'experiment1', 'AL_names')\n",
    "\n",
    "anomaly_index = 5\n",
    "test_fall_w_indices = find_true_regions(test_AL[:, anomaly_index])\n",
    "print(test_fall_w_indices)\n",
    "\n",
    "half_len = 100000\n",
    "test_data_indices = [(r[0] - half_len, r[1] + half_len) for r in test_fall_w_indices]\n",
    "X_test = [data2features(test_SD[r[0]:r[1], :24]) for r in test_data_indices]\n",
    "y_test = [[str(b) for b in test_AL[r[0]:r[1], anomaly_index]] for r in test_data_indices]\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "print(labels)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))\n",
    "\n",
    "# details\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "print(classification_report(\n",
    "    list(chain.from_iterable(y_test)), list(chain.from_iterable(y_pred)), labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "        \n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"transition features:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common())\n",
    "\n",
    "print(\"state features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda3b23-7ceb-4479-a4bb-8244e23951c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
