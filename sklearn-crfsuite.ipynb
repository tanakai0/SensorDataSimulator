{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7888dfbf-1d4b-4f42-aa67-6d36055e3ac9",
   "metadata": {},
   "source": [
    "# sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99db93c-f453-456e-b55e-e762a0f2977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ace_sklearn_crfsuite\n",
    "from pathlib import Path\n",
    "from ace_sklearn_crfsuite import metrics\n",
    "import numpy as np\n",
    "\n",
    "# self-made\n",
    "\n",
    "import src.utils as utils\n",
    "\n",
    "working_path = Path().resolve()\n",
    "layout_data_path = working_path / \"layout_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b72ad-bf34-48ad-8f3a-fbbbc24a02fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wandering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d154a0-56d5-4da4-8e02-241a80d1193d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data2features(data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        data.shape = (number of time, number of sensors).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : list of dict\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    T = data.shape[0]  # number of time\n",
    "    M = data.shape[1]  # number of sensors\n",
    "    for i in range(T):\n",
    "        d = data[i]\n",
    "        feature = {f\"x_{j}\": d[j] for j in range(M)}\n",
    "        # if i >= 1:\n",
    "        #     feature.update({f\"-1 x_{j}\": data[i-1][j] for j in range(M)})\n",
    "        # if i >= 60:\n",
    "        #     feature['sum_60'] = np.sum(data[i-60:i])\n",
    "        if i == 0:\n",
    "            feature[\"BOS\"] = True\n",
    "        if i == T - 1:\n",
    "            feature[\"EOS\"] = True\n",
    "        feature[\"bias\"] = 1\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "_type = \"raw\"\n",
    "data_folder_name = \"test_data_1\"\n",
    "path = layout_data_path / \"test_layout\" / data_folder_name\n",
    "reduced_SD_mat = utils.pickle_load(path / \"experiment1\", f\"reduced_SD_mat_{_type}_1\")\n",
    "reduced_AL_mat = utils.pickle_load(path / \"experiment1\", f\"reduced_AL_mat_{_type}_1\")\n",
    "SD_names = utils.pickle_load(path / \"experiment1\", \"SD_names\")\n",
    "AL_names = utils.pickle_load(path / \"experiment1\", \"AL_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f626bbe-c27b-45f8-82d9-b2f53df90084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13011\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "# X_train = [[{'a': True, 'b':1.2}, {'a': False, 'b':2}]]\n",
    "# y_train = [['True', 'False']]\n",
    "\n",
    "start = len(reduced_SD_mat) - 3000000\n",
    "end = len(reduced_SD_mat)\n",
    "\n",
    "X_train = [data2features(reduced_SD_mat[start:end, :24])]\n",
    "y_train = [[str(b) for b in reduced_AL_mat[start:end, 3]]]\n",
    "print(np.sum(reduced_AL_mat[start:end, 3]))\n",
    "\n",
    "c1, c2 = 0.1, 0.1\n",
    "crf = ace_sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\", c1=c1, c2=c2, max_iterations=100, all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "utils.pickle_dump(path / \"experiment1\", f\"crf_c1_{c1}_c2_{c2}\", crf)\n",
    "# test = utils.pickle_load(path / 'experiment1', f\"crf_c1_{c1}_c2_{c2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7dc6872-fb6c-494f-906b-9ec0b105dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['False', 'True']\n",
      "0.9998835758709718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      1.000     1.000     1.000   2987360\n",
      "        True      0.982     0.990     0.986     12640\n",
      "\n",
      "    accuracy                          1.000   3000000\n",
      "   macro avg      0.991     0.995     0.993   3000000\n",
      "weighted avg      1.000     1.000     1.000   3000000\n",
      "\n",
      "transition features:\n",
      "False  -> False   2.133736\n",
      "True   -> True    1.310936\n",
      "False  -> True    -7.315851\n",
      "True   -> False   -7.315851\n",
      "state features:\n",
      "0.897318 True     x_16\n",
      "0.840242 True     x_1\n",
      "0.810025 True     x_6\n",
      "0.788247 True     x_0\n",
      "0.612350 True     x_21\n",
      "0.576940 True     x_17\n",
      "0.515215 True     x_22\n",
      "0.496369 True     x_15\n",
      "0.481397 True     x_12\n",
      "0.479434 True     x_4\n",
      "0.476213 True     x_18\n",
      "0.458880 True     x_9\n",
      "0.428461 True     x_20\n",
      "0.369071 True     x_5\n",
      "0.339902 True     x_19\n",
      "0.323552 False    x_10\n",
      "0.287443 True     x_3\n",
      "0.284892 True     x_2\n",
      "0.227538 True     x_23\n",
      "0.217543 True     x_11\n",
      "0.194568 True     x_13\n",
      "0.193750 True     x_14\n",
      "0.182578 True     x_8\n",
      "0.143415 False    x_7\n",
      "0.026463 False    bias\n",
      "-0.026458 True     bias\n",
      "-0.143415 True     x_7\n",
      "-0.182578 False    x_8\n",
      "-0.193750 False    x_14\n",
      "-0.194568 False    x_13\n",
      "-0.217543 False    x_11\n",
      "-0.227538 False    x_23\n",
      "-0.284892 False    x_2\n",
      "-0.287443 False    x_3\n",
      "-0.323552 True     x_10\n",
      "-0.339902 False    x_19\n",
      "-0.369071 False    x_5\n",
      "-0.428461 False    x_20\n",
      "-0.458880 False    x_9\n",
      "-0.476213 False    x_18\n",
      "-0.479434 False    x_4\n",
      "-0.481397 False    x_12\n",
      "-0.496369 False    x_15\n",
      "-0.515215 False    x_22\n",
      "-0.576940 False    x_17\n",
      "-0.612350 False    x_21\n",
      "-0.788247 False    x_0\n",
      "-0.810025 False    x_6\n",
      "-0.840242 False    x_1\n",
      "-0.897318 False    x_16\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluation\n",
    "_type = \"raw\"\n",
    "data_folder_name = \"test_data_2\"\n",
    "path = layout_data_path / \"test_layout\" / data_folder_name\n",
    "test_SD = utils.pickle_load(path / \"experiment1\", f\"reduced_SD_mat_{_type}_1\")\n",
    "test_AL = utils.pickle_load(path / \"experiment1\", f\"reduced_AL_mat_{_type}_1\")\n",
    "test_SD_names = utils.pickle_load(path / \"experiment1\", \"SD_names\")\n",
    "test_AL_names = utils.pickle_load(path / \"experiment1\", \"AL_names\")\n",
    "\n",
    "X_test = [data2features(test_SD[start:end, :24])]\n",
    "y_test = [[str(b) for b in test_AL[start:end, 3]]]\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "print(labels)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average=\"weighted\", labels=labels))\n",
    "\n",
    "# details\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "print(\n",
    "    metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
    ")\n",
    "# print(classification_report(\n",
    "#     list(chain.from_iterable(y_test)), list(chain.from_iterable(y_pred)), labels=sorted_labels, digits=3\n",
    "# ))\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"transition features:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common())\n",
    "\n",
    "print(\"state features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2a73f-548b-4b69-a125-c27298d5b6cc",
   "metadata": {},
   "source": [
    "# Falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccab3ac-fb04-4e96-a0e9-3d240ed38891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['being semi-bedridden', 'being housebound', 'forgetting', 'wandering', 'fall while walking', 'fall while standing']\n",
      "(72722821, 28)\n",
      "(72722821, 6)\n",
      "951\n"
     ]
    }
   ],
   "source": [
    "def data2features(data):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        data.shape = (number of time, number of sensors).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : list of dict\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    T = data.shape[0]  # number of time\n",
    "    M = data.shape[1]  # number of sensors\n",
    "    for i in range(T):\n",
    "        d = data[i]\n",
    "        feature = {f\"x_{j}\": d[j] for j in range(M)}\n",
    "        # if i >= 1:\n",
    "        #     feature.update({f\"-1 x_{j}\": data[i-1][j] for j in range(M)})\n",
    "        if i >= 60:\n",
    "            feature[\"sum_60\"] = np.sum(data[i - 60 : i])\n",
    "        if i == 0:\n",
    "            feature[\"BOS\"] = True\n",
    "        if i == T - 1:\n",
    "            feature[\"EOS\"] = True\n",
    "        feature[\"bias\"] = 1\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "_type = \"raw\"\n",
    "data_folder_name = \"test_data_1\"\n",
    "path = layout_data_path / \"test_layout\" / data_folder_name\n",
    "reduced_SD_mat = utils.pickle_load(path / \"experiment1\", f\"reduced_SD_mat_{_type}_1\")\n",
    "reduced_AL_mat = utils.pickle_load(path / \"experiment1\", f\"reduced_AL_mat_{_type}_1\")\n",
    "SD_names = utils.pickle_load(path / \"experiment1\", \"SD_names\")\n",
    "AL_names = utils.pickle_load(path / \"experiment1\", \"AL_names\")\n",
    "anomaly_index = 4\n",
    "print(AL_names)\n",
    "print(reduced_SD_mat.shape)\n",
    "print(reduced_AL_mat.shape)\n",
    "print(np.sum(reduced_AL_mat[:, anomaly_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73effa79-340a-4b0b-b2af-f82445d3aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1374529, 1374558), (1725780, 1725816), (3124630, 3124660), (5692493, 5692525), (6864771, 6864805), (9055579, 9055612), (11664388, 11664419), (12236306, 12236337), (14427490, 14427523), (14964067, 14964101), (17422324, 17422355), (17578809, 17578833), (19145927, 19145957), (19860798, 19860819), (25014612, 25014640), (28189736, 28189766), (28661366, 28661397), (32428981, 32429016), (35107261, 35107287), (42253971, 42254002), (42500408, 42500443), (42510791, 42510823), (44901872, 44901905), (46524635, 46524663), (50442221, 50442254), (52768217, 52768252), (54453519, 54453535), (56013038, 56013071), (60706084, 60706115), (61562287, 61562328), (64855788, 64855812)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_true_regions(arr):\n",
    "    \"\"\"\n",
    "    Find continuous True regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy.ndarray\n",
    "        arr.shape = (n, ).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    start_end_indices : list of tuple of int\n",
    "        start_end_indices[i] = (index of start, index of end) of ith regions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> find_true_regions(np.array([False, True, True, False, False, True, True, True, False, True]))\n",
    "    >>> [(1, 3), (5, 8), (9, 10)]\n",
    "    \"\"\"\n",
    "    indices = np.where(arr)[0]\n",
    "    split_points = np.where(np.diff(indices) > 1)[0] + 1\n",
    "    ranges = np.split(indices, split_points)\n",
    "    start_end_indices = [(r[0], r[-1] + 1) for r in ranges]\n",
    "    return start_end_indices\n",
    "\n",
    "\n",
    "fall_indices = find_true_regions(reduced_AL_mat[:, anomaly_index])\n",
    "print(fall_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154453d0-024d-47ca-8862-6b0888f8c9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "# X_train = [[{'a': True, 'b':1.2}, {'a': False, 'b':2}]]\n",
    "# y_train = [['True', 'False']]\n",
    "\n",
    "half_len = 100000\n",
    "data_indices = [(r[0] - half_len, r[1] + half_len) for r in fall_indices]\n",
    "X_train = [data2features(reduced_SD_mat[r[0] : r[1], :24]) for r in data_indices]\n",
    "y_train = [\n",
    "    [str(b) for b in reduced_AL_mat[r[0] : r[1], anomaly_index]] for r in data_indices\n",
    "]\n",
    "\n",
    "crf = ace_sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940a6167-1994-420a-9037-5d6a375a8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(490810, 490831), (1336048, 1336087), (3846561, 3846598), (5726091, 5726115), (7264576, 7264612), (8467347, 8467376), (8637608, 8637629), (12273516, 12273542), (12415247, 12415279), (12947694, 12947728), (14687685, 14687707), (15938852, 15938877), (16378152, 16378184), (17209211, 17209235), (17336877, 17336904), (26007867, 26007905), (27090838, 27090865), (30423831, 30423859), (31546022, 31546049), (32037386, 32037407), (32684648, 32684680), (35247375, 35247410), (35675941, 35675968), (37134881, 37134912), (37644872, 37644899), (38288556, 38288586), (38353858, 38353886), (40288372, 40288404), (40885306, 40885350), (42196073, 42196109), (42283292, 42283328), (42575656, 42575680), (45375260, 45375292), (47692682, 47692726), (47731128, 47731166), (50295690, 50295721), (50825838, 50825871), (51701206, 51701243), (54899686, 54899723), (55245380, 55245406), (56026406, 56026438), (58011056, 58011085), (58204875, 58204908), (62549513, 62549546), (66668902, 66668929), (69690030, 69690058), (70516246, 70516281), (73759531, 73759553)]\n",
      "['False', 'True']\n",
      "0.9997373915994217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanakai\\Documents\\git\\Simulator\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tanakai\\Documents\\git\\Simulator\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      1.000     1.000     1.000   9599788\n",
      "        True      0.000     0.000     0.000      1681\n",
      "\n",
      "    accuracy                          1.000   9601469\n",
      "   macro avg      0.500     0.500     0.500   9601469\n",
      "weighted avg      1.000     1.000     1.000   9601469\n",
      "\n",
      "transition features:\n",
      "False  -> False   0.407204\n",
      "True   -> True    0.060465\n",
      "True   -> False   -7.464795\n",
      "False  -> True    -7.484195\n",
      "state features:\n",
      "0.653863 False    EOS\n",
      "0.582265 False    BOS\n",
      "0.540445 False    x_2\n",
      "0.516878 False    x_11\n",
      "0.491037 False    x_0\n",
      "0.476786 False    x_12\n",
      "0.414085 True     x_23\n",
      "0.327168 False    x_14\n",
      "0.326480 False    x_10\n",
      "0.266219 True     x_18\n",
      "0.252324 False    x_1\n",
      "0.231374 True     x_15\n",
      "0.223698 True     x_3\n",
      "0.223143 False    x_16\n",
      "0.196431 False    x_7\n",
      "0.172946 True     x_6\n",
      "0.170801 False    x_22\n",
      "0.152803 True     bias\n",
      "0.105159 False    x_20\n",
      "0.092593 False    x_17\n",
      "0.064207 True     x_5\n",
      "0.015528 False    x_19\n",
      "0.007659 False    x_21\n",
      "0.002661 False    x_8\n",
      "0.002527 False    x_4\n",
      "0.000841 False    x_9\n",
      "0.000416 True     sum_60\n",
      "-0.000416 False    sum_60\n",
      "-0.000841 True     x_9\n",
      "-0.002527 True     x_4\n",
      "-0.002661 True     x_8\n",
      "-0.007659 True     x_21\n",
      "-0.015528 True     x_19\n",
      "-0.064207 False    x_5\n",
      "-0.092593 True     x_17\n",
      "-0.105159 True     x_20\n",
      "-0.152803 False    bias\n",
      "-0.170801 True     x_22\n",
      "-0.172946 False    x_6\n",
      "-0.196431 True     x_7\n",
      "-0.223143 True     x_16\n",
      "-0.223698 False    x_3\n",
      "-0.231374 False    x_15\n",
      "-0.252324 True     x_1\n",
      "-0.266219 False    x_18\n",
      "-0.326480 True     x_10\n",
      "-0.327168 True     x_14\n",
      "-0.414085 False    x_23\n",
      "-0.476786 True     x_12\n",
      "-0.491037 True     x_0\n",
      "-0.516878 True     x_11\n",
      "-0.540445 True     x_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanakai\\Documents\\git\\Simulator\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluation\n",
    "_type = \"raw\"\n",
    "data_folder_name = \"test_data_2\"\n",
    "path = layout_data_path / \"test_layout\" / data_folder_name\n",
    "test_SD = utils.pickle_load(path / \"experiment1\", f\"reduced_SD_mat_{_type}_1\")\n",
    "test_AL = utils.pickle_load(path / \"experiment1\", f\"reduced_AL_mat_{_type}_1\")\n",
    "test_SD_names = utils.pickle_load(path / f\"experiment1\", \"SD_names\")\n",
    "test_AL_names = utils.pickle_load(path / \"experiment1\", \"AL_names\")\n",
    "\n",
    "anomaly_index = 5\n",
    "test_fall_indices = find_true_regions(test_AL[:, anomaly_index])\n",
    "print(test_fall_indices)\n",
    "\n",
    "half_len = 100000\n",
    "test_data_indices = [(r[0] - half_len, r[1] + half_len) for r in test_fall_indices]\n",
    "X_test = [data2features(test_SD[r[0] : r[1], :24]) for r in test_data_indices]\n",
    "y_test = [\n",
    "    [str(b) for b in test_AL[r[0] : r[1], anomaly_index]] for r in test_data_indices\n",
    "]\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "print(labels)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average=\"weighted\", labels=labels))\n",
    "\n",
    "# details\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "print(\n",
    "    metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
    ")\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"transition features:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common())\n",
    "\n",
    "print(\"state features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda3b23-7ceb-4479-a4bb-8244e23951c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
